# Lukifer23 â€” On-Device AI, Apple-Silicon First

**I build privacy-first, on-device AI for Apple Silicon and Android** â€” local LLM chat (**IRISStar**), a low-latency Mac voice assistant (**MacBot**), chess engines that play *and* teach (**Matrix0**, **GemmaFischer**), and a high-fidelity PNGâ†’SVG tool (**svg-X**).

- **Focus:** Apple Silicon (M-series) & Snapdragon â€¢ local LLMs â€¢ realtime voice â€¢ chess engines â€¢ vectorization  
- **Philosophy:** Results > rhetoric. If itâ€™s not measurable, itâ€™s not done.

---

## Now
- Finalizing **GemmaFischer**: LoRA adapters on HF + tutor-mode evaluations + transcript examples  
- Next up: **IRISStar** (packaging, device matrix) â†’ **MacBot** (demos, latency table) â†’ **Matrix0** (checkpoint, Elo ladder)

> Iâ€™ll add numbers and binaries here *after* theyâ€™re published in each repoâ€™s Releases.

---

## Selected Work (with status)

**Legend:** ğŸš€ available â€¢ ğŸ› ï¸ active update â€¢ ğŸ”¬ research/prototype

- ğŸš€ **[svg-X](https://github.com/lukifer23/svg-X)** â€” PNGâ†’SVG with quantization + curve fitting (desktop/CLI).  
  *Cross-platform app; releases available in the repo.*

- ğŸ› ï¸ **[GemmaFischer](https://github.com/lukifer23/GemmaFischer)** â€” MoE chess LLM (UCI + tutor mode).  
  *Linking LoRA adapters on HF and adding a small eval harness + tutor transcripts.*

- ğŸ› ï¸ **[IRISStar](https://github.com/lukifer23/IRISStar)** â€” Android offline LLM client (GGUF) tuned for Snapdragon/Apple GPU backends.  
  *Packaging and a concise device/perf matrix are in progress.*

- ğŸ› ï¸ **[MacBot](https://github.com/lukifer23/MacBot)** â€” local VAD â†’ Whisper v3 â†’ LLM â†’ TTS with a live dashboard (macOS).  
  *Short demo clips and a simple latency table are coming alongside a pre-alpha app bundle.*

- ğŸ› ï¸ **[Matrix0](https://github.com/lukifer23/Matrix0)** â€” self-play chess engine with SSL heads and a web UI.  
  *Publishing a small checkpoint and a provisional Elo ladder vs a fixed baseline.*

- ğŸ”¬ **[FusterCluck](https://github.com/lukifer23/FusterCluck)** â€” compact text-only LLM training pipeline for Apple Silicon.  
  *Early-stage; staged curriculum and tooling are public.*

---

## How I work
- **On-device first:** privacy by default; minimal dependencies; clear fallbacks.  
- **Reproducible setups:** pinned configs and end-to-end quickstarts.  
- **Evidence over adjectives:** when a metric or binary exists, it appears in the repoâ€™s **Releases** and **/results**.

---

## Where to find releases
- Each project publishes artifacts **in its own repo** under **Releases** when ready.  
- Iâ€™ll surface notable numbers (latency, tokens/s, Elo, size deltas) here once theyâ€™re live.

---

## Contact
- X / email / website: *add your links here*  
- Issues and PRs welcome.
